# -*- coding: utf-8 -*-
"""v6 tercer-avance-tesis

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uATSx-WQaYPUVOXFOjuiI9p6CFxhtAX9

#Avances de tesis doctorales III

Se presentara un jupyter notebook con un script para la realización del modelo de predicción utilizando un CNN

En esta sección se cargaran las librerias necesarias para el uso de la libreta, en dado caso que no se tenga instaladas, se dejaran los comandos necesarios para la instalación de cada una.
En dado caso que no tengan las librearias instaladas, eliminen el simbolo de "#" para que deje ser comentario (verde) y sea codigo y asi poder instalar la libreria necesaria.
En dado caso no haya puesto alguna libreria que se necesite, para instalarla usen el siguiente formato:


```
!pip install -nombredelibreriavaaqui-
```
"""

try:
    import rasterio
except ImportError:
    !pip install  rasterio
    import rasterio

! pip install keras-tuner --upgrade

! pip install tqdm

! pip install keract

#! pip install geopandas
#! pip install rasterio
#! pip install tensorflow
#! pip install keras
#! pip install seaborn
#! pip install -U scikit-learn
#! pip install pandas
#! pip install numpy
#! pip install matplotlib
#! pip install plotly
#! pip install python-time
#! pip install pillow
#! pip install opencv-python

import time
import sklearn
import cv2
import os
import keras
import shutil
import random

import matplotlib.pyplot    as plt
import plotly.graph_objects as go
import seaborn              as sns
import numpy                as np
import pandas               as pd
import tensorflow           as tf
import keras_tuner          as kt

from tqdm                    import tqdm
from sklearn                 import preprocessing, datasets
from sklearn.metrics         import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import train_test_split
from sklearn.preprocessing   import OneHotEncoder,LabelEncoder, OrdinalEncoder, RobustScaler, OneHotEncoder
from keras.optimizers        import Adam
from google.colab            import drive
from rasterio.plot           import show
from rasterio.enums          import Resampling
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D
from tensorflow.keras.models import Model
from sklearn.model_selection import RandomizedSearchCV
from kerastuner.tuners       import RandomSearch
from keract                  import get_activations, display_activations
from keras.models            import Sequential
from keras.layers            import Dense, Flatten
from keras.layers            import Conv2D, MaxPooling2D, UpSampling2D
from keras.callbacks         import EarlyStopping, ReduceLROnPlateau
from keras.models            import Sequential
from keras.layers            import Conv2D, MaxPooling2D, Flatten, Dense, Reshape

from keras                   import backend as K

"""Cargando las librerias necesarias, ahora se comienza con la lectura de los archivos, en este caso estan desde la nube de google drive y en la siguiente linea:"""

drive.mount('/content/drive')

# Definir la carpeta con las imágenes
zona_uno = '/content/drive/MyDrive/2018-2022 NDVI NBR/zona-uno_v2'

# Obtener la lista de archivos de imágenes
file_list = os.listdir(zona_uno)
image_files = [file for file in file_list if file.endswith(('.tif'))] #Se crea una lista con los nombres de los archivos
print(f"La carpeta contiene " + str(len(image_files)) + " imágenes") #Imprimir el numero de imagenes leidas

import os
import rasterio

# Definir la carpeta con las imágenes
zona_uno = '/content/drive/MyDrive/2018-2022 NDVI NBR/zona-uno_v2'

# Obtener la lista de archivos de imágenes
file_list = os.listdir(zona_uno)
image_files = [file for file in file_list if file.endswith(('.tif'))]

print(f"La carpeta contiene {len(image_files)} imágenes")

# Iterar sobre cada archivo y obtener el tamaño con Rasterio
for image_file in image_files:
    image_path = os.path.join(zona_uno, image_file)

    with rasterio.open(image_path) as src:
        width = src.width
        height = src.height
        count = src.count  # Número de bandas

    print(f"Imagen: {image_file}, Tamaño: {width} x {height}, Número de bandas: {count}")

"""####Reshape

En esta parte se realiza un reshape en caso que sea necesario para las imagenenes, se separan los dos canales NBR y NDVI.
"""

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/nbr'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

carpeta_salida = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/nbr'

nodata_value = -9999

for image in image_files:
    # Le damos el path completo de cada imagen
    file_path = os.path.join(zona_uno, image)

    with rasterio.open(file_path) as src:
        # Leer los datos como una matriz numpy
        image_array = src.read(1, masked=True)
        mask = src.read_masks(1)

    # Excluir los valores de nodata
    image_array = np.ma.masked_where(image_array == nodata_value, image_array)

    # Aplicar la máscara al array de la imagen
    image_array = np.ma.masked_array(image_array, mask)

    resized_image = cv2.resize(image_array, (50, 50))  # Resize

    output_path = os.path.join(carpeta_salida, image)  # Guardamos

    resized_image = np.nan_to_num(resized_image)

    # Guardar la imagen redimensionada
    cv2.imwrite(output_path, resized_image)

carpeta = carpeta_salida

# Obtener la lista de archivos en la carpeta
archivos = os.listdir(carpeta)

for archivo in archivos:
    # Construir la ruta completa del archivo
    ruta_archivo = os.path.join(carpeta, archivo)

    # Abrir el archivo TIFF con rasterio
    with rasterio.open(ruta_archivo) as imagen:
        image_array = imagen.read()
        print(str(image_array.shape))

# Obtener la lista de archivos de imágenes
file_list = os.listdir(carpeta_salida)
image_files = [file for file in file_list if file.endswith(('.tif'))] #Se crea una lista con los nombres de los archivos
print(f"La carpeta contiene " + str(len(image_files)) + " imágenes") #Imprimir el numero de imagenes leidas

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

carpeta_salida = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2'

nodata_value = -9999

for image in image_files:
    # Le damos el path completo de cada imagen
    file_path = os.path.join(zona_uno, image)

    with rasterio.open(file_path) as src:
        # Leer los datos como una matriz numpy
        image_array = src.read(1, masked=True)
        mask = src.read_masks(1)

    # Excluir los valores de nodata
    image_array = np.ma.masked_where(image_array == nodata_value, image_array)

    # Aplicar la máscara al array de la imagen
    image_array = np.ma.masked_array(image_array, mask)

    resized_image = cv2.resize(image_array, (50, 50))  # Resize

    output_path = os.path.join(carpeta_salida, image)  # Guardamos

    resized_image = np.nan_to_num(resized_image)

    # Guardar la imagen redimensionada
    cv2.imwrite(output_path, resized_image)

carpeta = carpeta_salida

# Obtener la lista de archivos en la carpeta
archivos = os.listdir(carpeta)

for archivo in archivos:
    # Construir la ruta completa del archivo
    ruta_archivo = os.path.join(carpeta, archivo)

    # Abrir el archivo TIFF con rasterio
    with rasterio.open(ruta_archivo) as imagen:
        image_array = imagen.read()
        print(str(image_array.shape))

# Obtener la lista de archivos de imágenes
file_list = os.listdir(carpeta_salida)
image_files = [file for file in file_list if file.endswith(('.tif'))] #Se crea una lista con los nombres de los archivos
print(f"La carpeta contiene " + str(len(image_files)) + " imágenes") #Imprimir el numero de imagenes leidas

def desplegar_imagen(ruta_imagen, cmap='viridis'):
    with rasterio.open(ruta_imagen) as src:
        img = src.read(1)  # Lee la primera banda de la imagen

        # Muestra la imagen con una escala de colores
        plt.figure(figsize=(8, 6))
        plt.imshow(img, cmap=cmap)  # Selecciona el mapa de colores
        plt.colorbar()
        plt.title('TempMax')
        plt.show()

# Llama a la función con la ruta de la imagen de índice de población
ruta_poblacion = '/content/drive/MyDrive/2018-2022 NDVI NBR/ambientales/2015.tif'
desplegar_imagen(ruta_poblacion, cmap='YlOrRd')

def desplegar_imagen(ruta_imagen, cmap='viridis'):
    with rasterio.open(ruta_imagen) as src:
        img = src.read(1)  # Lee la primera banda de la imagen

        # Muestra la imagen con una escala de colores
        plt.figure(figsize=(8, 6))
        plt.imshow(img, cmap=cmap)  # Selecciona el mapa de colores
        plt.colorbar()
        plt.title('Index population')
        plt.show()

# Llama a la función con la ruta de la imagen de índice de población
ruta_poblacion = '/content/drive/MyDrive/2018-2022 NDVI NBR/poblacion/population-index-2020.tif'
desplegar_imagen(ruta_poblacion, cmap='YlOrRd')

def desplegar_imagen(ruta_imagen, cmap='viridis'):
    with rasterio.open(ruta_imagen) as src:
        img = src.read(1)  # Lee la primera banda de la imagen

        # Muestra la imagen con una escala de colores
        plt.figure(figsize=(8, 6))
        plt.imshow(img, cmap=cmap)  # Selecciona el mapa de colores
        plt.colorbar()
        plt.title('Uso de suelo y vegetación')
        plt.show()

# Llama a la función con la ruta de la imagen de uso de suelo
ruta_uso_suelo = '/content/drive/MyDrive/2018-2022 NDVI NBR/landcover/landcover.tif'
desplegar_imagen(ruta_uso_suelo, cmap='tab20')

"""Aqui veremos las imagenes"""

def desplegar_imagen_NBR(ruta_imagen):
    with rasterio.open(ruta_imagen) as src:
        img = src.read(1)  # Lee la primera banda de la imagen

        # Muestra la imagen con una escala de colores
        plt.figure(figsize=(8, 6))
        plt.imshow(img, cmap='RdYlGn')  # Selecciona el mapa de colores
        plt.colorbar()
        plt.title('NBR')
        plt.show()

# Llama a la función con la ruta de la imagen
desplegar_imagen_NBR('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/nbr/LC08_030046_20140127.tif')

def desplegar_imagen_NDVI(ruta_imagen):
    with rasterio.open(ruta_imagen) as src:
        img = src.read(1)  # Lee la primera banda de la imagen

        # Muestra la imagen con una escala de colores
        plt.figure(figsize=(8, 6))
        plt.imshow(img, cmap='RdYlGn')  # Selecciona el mapa de colores
        plt.colorbar()
        plt.title('NDVI')
        plt.show()

# Llama a la función con la ruta de la imagen
desplegar_imagen_NDVI('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2/LC08_030046_20140127.tif')

#desplegando_imagen_NBR('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2/LC08_030046_20140228.tif')

#desplegando_imagen_NBR('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2/Copia de LC08_030046_20140401.tif')

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/multiband/'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

NBR_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/nbr'
NDVI_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2'

# Directorio de entrada para NBR
NDVI_dic = "/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2"

# Directorio de salida para las imágenes de NBR en la carpeta "multiband"
output_directory = "/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/multiband"

# Obtener la lista de archivos en el directorio NBR
image_files = os.listdir(NDVI_dic)

for image in image_files:
    # Le damos el path completo de cada imagen NBR
    file_path_NBR = os.path.join(NBR_dic, image)

    # Crear el path de salida para la imagen en la carpeta "multiband"
    output_path = os.path.join(output_directory, image)

    # Copiar la imagen de NBR a la carpeta "multiband"
    shutil.copy(file_path_NBR, output_path)

# Nota: Asegúrate de que las imágenes tengan el mismo nombre en el directorio NBR y que deseas copiar todas las imágenes sin filtrar.

with rasterio.open('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/multiband/LC08_030046_20140111.tif') as src: #Abrimos con Rasterio
        image_array = src.read() #Leemos el array de la imagen

image_array.shape

multiband_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/multiband/'

train_img = []

for image in image_files:
    #Le damos el path completo de cada TIF imagen
    file_path = os.path.join(multiband_dic, image)

    with rasterio.open(file_path) as src: #Abrimos con Rasterio
        image_array = src.read() #Leemos el array de la imagen

    train_img.append(image_array)

train_img_2 = np.stack([img for img in train_img], axis=0)
print(train_img_2.shape)

# Assuming you have a 2-channel TIF image with shape (2, 48, 40)
image = train_img_2

# Reshape the image to (48, 40, 2)
reshaped_image = np.transpose(image, (0, 2, 3, 1))

print(reshaped_image.shape)

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/target'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/target'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/zonasegmentada'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

# Directorio de entrada para NBR
zona_uno = '/content/drive/MyDrive/2018-2022 NDVI NBR/zona-uno_v2'

# Directorio de salida para las imágenes de NBR en la carpeta "multiband"
output_directory = "/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/target"

# Directorio de salida para las imágenes segmentadas
carpeta_procesada = "/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/segmentadas"

# Valor de nodata
nodata_value = -9999

# Obtener la lista de archivos en la carpeta de entrada
archivos_tiff = [archivo for archivo in os.listdir(zona_uno) if archivo.endswith('.tif')]

# Crear la carpeta de salida si no existe
if not os.path.exists(output_directory):
    os.makedirs(output_directory)

# Crear la carpeta procesada si no existe
if not os.path.exists(carpeta_procesada):
    os.makedirs(carpeta_procesada)

# Recorrer cada archivo en la carpeta
for archivo_tiff in archivos_tiff:
    # Construir la ruta completa al archivo TIFF de entrada
    ruta_tiff_entrada = os.path.join(zona_uno, archivo_tiff)

    with rasterio.open(ruta_tiff_entrada) as src:
        # Leer los datos como una matriz numpy
        image_array = src.read(1, masked=True)
        mask = src.read_masks(1)

    # Excluir los valores de nodata
    image_array = np.ma.masked_where(image_array == nodata_value, image_array)

    # Aplicar la máscara al array de la imagen
    image_array = np.ma.masked_array(image_array, mask)

    # Resize de la imagen
    resized_image = cv2.resize(image_array, (50, 50))

    # Construir la ruta completa al archivo TIFF de salida
    ruta_tiff_salida = os.path.join(output_directory, f'resized_{archivo_tiff}')

    # Guardar la imagen redimensionada
    cv2.imwrite(ruta_tiff_salida, resized_image)

    # Abrir el archivo redimensionado con rasterio
    with rasterio.open(ruta_tiff_salida) as src:
        # Leer los datos como una matriz numpy
        datos_resized = src.read(1, masked=True)

        # Excluir los valores de nodata
        datos_sin_nodata_resized = np.ma.masked_where(datos_resized == nodata_value, datos_resized)

        # Segmentar la imagen según los valores dados (>0.6 y <0.6)
        segmentacion = np.where(datos_sin_nodata_resized > 0.6, 1, 0)

    # Construir la ruta completa al archivo TIFF segmentado de salida
    ruta_segmentada = os.path.join(carpeta_procesada, f'segmentada_{archivo_tiff}')

    # Guardar la imagen segmentada como un nuevo archivo TIFF
    with rasterio.open(
        ruta_segmentada,
        'w',
        driver='GTiff',
        height=segmentacion.shape[0],
        width=segmentacion.shape[1],
        count=1,
        dtype=str(segmentacion.dtype),
        crs=src.crs,
        transform=src.transform,
    ) as dst:
        dst.write(segmentacion, 1)

with rasterio.open('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/segmentadas/segmentada_LC08_030046_20140111.tif') as src: #Abrimos con Rasterio
        image_array = src.read() #Leemos el array de la imagen

image_array.shape

target_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/segmentadas'

# Obtener la lista de archivos de imágenes
file_list = os.listdir(target_dic)
image_files = [file for file in file_list if file.endswith(('.tif'))] #Se crea una lista con los nombres de los archivos
print(f"La carpeta contiene " + str(len(image_files)) + " imágenes") #Imprimir el numero de imagenes leidas

train_img2 = []

for image in image_files:
    #Le damos el path completo de cada TIF imagen
    file_path = os.path.join(target_dic, image)

    with rasterio.open(file_path) as src: #Abrimos con Rasterio
        image_array = src.read() #Leemos el array de la imagen

    train_img2.append(image_array)

train_img_3 = np.stack([img for img in train_img2], axis=0)
print(train_img_2.shape)

# Assuming you have a 2-channel TIF image with shape (2, 48, 40)
image = train_img_3

# Reshape the image to (48, 40, 2)
reshaped_image_2 = np.transpose(image, (0, 2, 3, 1))

print(reshaped_image_2.shape)

"""# Modelos CNN

En esta seccion encontraremos los modelos para el algoritmo de un solo canal (NDVI) que prediga el NBR y de dos canales (NBR + NDVI) para predecir NBR

## Modelo 1

#### X Y

Definicion de Output e input del primer modelo
"""

y = reshaped_image_2

X = reshaped_image

# Assuming reshaped_image is your features and y is your labels
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

y_train.shape

y_val.shape

X_train.shape

X_val.shape

show(y_train[4, :, :, 0])

show(y_val[1, :, :, 0])

show(X_train[4, :, :, 0])

show(X_val[1, :, :, 0])

"""Con2D
MAx
Con2D
Max
Con2D
Max

Flatten
FC - Dense
FC - Dense}

Input Shape - 200 200 * 1
Output Shape 40000 neuronas - Activacion Sigmoide
1d transformar a 2D

Resize de 40,000 a 200 x 200

Cambiarle a 0 - despues cambiarle a -1

cambiar las imagenes de NBR a vectores de 40,000 y esta sera la Y de target --- Activacion sigomoide.

Para segunda version del modelo
Utilizar Dropout de 0.2

Utilizar Callbacks

**Meter los Callbacks y dropouts - **

**Intentar ver si combiene utilizar los segmentations**

**Descargar variables ambientales - antropogenicas **
"""

#import cv2
#import matplotlib.pyplot as plt
#path = "/content/drive/MyDrive/2018-2022 NDVI NBR/Captura de pantalla 2023-11-15 085354.png"
#img = cv2.imread(path)
#plt.imshow(img)

"""### Modelo convulcional

Aqui se intenta realizar un modelo con un canal de NDVI y me de el NBR
"""

# Define the neural network architecture
model = Sequential()

# Convolutional and max-pooling layers
model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(50, 50, 1)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

# Flatten layer
model.add(Flatten())

# Fully connected layers
model.add(Dense(2500, activation='sigmoid'))

# Reshape to 2D
model.add(Reshape((50, 50, 1)))

# Compila el modelo
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

# Print model summary
model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %time historial = model.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial)

"""## Modelo 2

"""

salida = model.predict(y_train)
plt.imshow(salida[0, :, :, 0])

"""### Union canales

Procesamiento para unir los dos calaes para gener una imagen con dos canales (NBR + NDVI)
"""

# Ruta de la carpeta a limpiar
ruta_carpeta = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/doscanales/'

# Verificar si la carpeta existe
if os.path.exists(ruta_carpeta):
    # Eliminar todo el contenido de la carpeta
    for filename in os.listdir(ruta_carpeta):
        file_path = os.path.join(ruta_carpeta, filename)
        try:
            if os.path.isfile(file_path) or os.path.islink(file_path):
                os.unlink(file_path)
            elif os.path.isdir(file_path):
                shutil.rmtree(file_path)
        except Exception as e:
            print(f"No se pudo eliminar {file_path}. Motivo: {e}")
    print("Contenido de la carpeta eliminado exitosamente.")
else:
    print("La carpeta no existe.")

NBR_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/nbr'
NDVI_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/ndvi2'

combined_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/doscanales'

NBR_img = []
NDVI_img = []

# Check if the combined_dic directory exists, if not, create it
if not os.path.exists(combined_dic):
    os.makedirs(combined_dic)

# Obtener la lista de archivos en NBR_dic
image_files = [archivo for archivo in os.listdir(NBR_dic) if archivo.endswith('.tif')]

# Leer las imágenes en NBR_dic y NDVI_dic, y combinarlas en un nuevo archivo
for image in image_files:
    # Le damos el path completo de cada NBR imagen
    file_path_NBR = os.path.join(NBR_dic, image)
    # Le damos el path completo de cada NDVI imagen
    file_path_NDVI = os.path.join(NDVI_dic, image)

    # Abrir las imágenes con rasterio
    with rasterio.open(file_path_NBR) as src_NBR, rasterio.open(file_path_NDVI) as src_NDVI:
        # Leer las bandas de las imágenes
        NBR_array = src_NBR.read()
        NDVI_array = src_NDVI.read()

        # Crear el perfil del archivo combinado
        profile = src_NBR.profile
        profile.update(count=2)

        # Crear el path del archivo combinado
        combined_file_path = os.path.join(combined_dic, image)

        # Escribir las imágenes combinadas en el nuevo TIF file
        with rasterio.open(combined_file_path, 'w', **profile) as dst:
            # Escribir la primera imagen en el nuevo TIF file
            dst.write(NBR_array, indexes=[1])

            # Escribir la segunda imagen en el nuevo TIF file
            dst.write(NDVI_array, indexes=[2])

# Optional: Agregar las imágenes combinadas a las listas NBR_img y NDVI_img
    NBR_img.append(NBR_array)
    NDVI_img.append(NDVI_array)

# NBR_img[0].shape
len(NBR_img)

# NDVI_img[0].shape
len(NDVI_img)

train_img = []

for i in range(10):
    train_img.append([NBR_img[i], NDVI_img[i]])

train_img[0]

input_shapes = set(np.array(image).shape for image in train_img)

print("Formas de las imágenes NBR de entrada:")
print(input_shapes)

for image in image_files:
    #Le damos el path completo de cada NBR imagen
    file_path_NBR = os.path.join(NBR_dic, image)
    #Le damos el path completo de cada NDVI imagen
    file_path_NDVI = os.path.join(NDVI_dic, image)

    NBR = rasterio.open(file_path_NBR)
    NDVI = rasterio.open(file_path_NDVI)

    profile = NBR.profile
    profile.update(count=2)

    with rasterio.open('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/doscanales/' + image,
                       'w', **profile) as dst:
        # Write the first image to the new TIF file
        dst.write(NBR.read(), indexes=[1])

        # Write the second image to the new TIF file
        dst.write(NDVI.read(), indexes=[2])

with rasterio.open('/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/doscanales/LC08_030046_20140316.tif') as src: #Abrimos con Rasterio
        image_array = src.read() #Leemos el array de la imagen

image_array.shape

multiband_dic = '/content/drive/MyDrive/2018-2022 NDVI NBR/preprocep/doscanales/'

train_img3 = []

for image in image_files:
    #Le damos el path completo de cada TIF imagen
    file_path = os.path.join(multiband_dic, image)

    with rasterio.open(file_path) as src: #Abrimos con Rasterio
        image_array = src.read() #Leemos el array de la imagen

    train_img3.append(image_array)

train_img_4 = np.stack([img for img in train_img3], axis=0)
print(train_img_2.shape)

# Assuming you have a 2-channel TIF image with shape (2, 48, 40)
image = train_img_4

# Reshape the image to (48, 40, 2)
reshaped_image2 = np.transpose(image, (0, 2, 3, 1))

print(reshaped_image2.shape)

reshaped_image2 = reshaped_image2

"""### X Y

Aqui se define la "X" (input) y "y" (output)
"""

ym2 = reshaped_image_2

Xm2 = reshaped_image2

X_train, X_test, y_train, y_test = train_test_split(Xm2, ym2, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

show(y_train[2, :, :, 0])

X_train.shape

show(X_train[5, :, :, 0])

"""### Modelo convulcional

Aqui se intenta con imagenes de dos canales y que nomas le salga un canal
"""

from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Reshape

# Define the neural network architecture
model2 = Sequential()

# Convolutional and max-pooling layers
model2.add(Conv2D(64, (3, 3), activation='relu', input_shape=(50, 50, 2)))  # Change input shape to (50, 50, 2)
model2.add(MaxPooling2D((2, 2)))
model2.add(Conv2D(128, (3, 3), activation='relu'))
model2.add(MaxPooling2D((2, 2)))

# Flatten layer
model2.add(Flatten())

# Fully connected layers
model2.add(Dense(2500, activation='sigmoid'))

# Reshape to 2D
model2.add(Reshape((50, 50, 1)))

# Compile the model
model2.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

# Print model summary
model2.summary()

# Commented out IPython magic to ensure Python compatibility.
# %time historial2 = model2.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_val, X_val))

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial2)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial2)

salida = model2.predict(X_train)
plt.imshow(salida[0, :, :, 0])

# Display the predicted output (1st sample) using matplotlib
plt.imshow(salida[0, :, :, 0], cmap='RdYlGn')  # Assuming it's a grayscale image
plt.colorbar()
plt.title('Predicted Output')
plt.show()

# Get the range of the predicted image
predicted_range = np.ptp(salida[3, :, :, 0])  # Peak-to-peak (max-min) value
print(f"Predicted Image Range: {predicted_range}")

"""## Comparación un canal vs dos canales"""

import matplotlib.pyplot as plt

def plot_metrics(hist, title):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # Plot accuracy
    ax1.plot(hist.history["accuracy"])
    ax1.plot(hist.history["val_accuracy"])
    ax1.set_title("Model Accuracy")
    ax1.set_ylabel("Accuracy")
    ax1.set_xlabel("Epoch")
    ax1.legend(["Train", "Validation"], loc="upper left")
    ax1.set_ylim((0, 1))
    ax1.grid()

    # Plot loss
    ax2.plot(hist.history["loss"])
    ax2.plot(hist.history["val_loss"])
    ax2.set_title("Model Loss")
    ax2.set_ylabel("Loss")
    ax2.set_xlabel("Epoch")
    ax2.legend(["Train", "Validation"], loc="upper left")
    ax2.set_ylim((0, 1))
    ax2.grid()

    plt.suptitle(title)
    plt.show()

# Example usage:
# Assuming you have historial and historial2
plot_metrics(historial, "Model Metrics - Un canal")
plot_metrics(historial2, "Model Metrics - Dos canales")

import matplotlib.pyplot as plt

def plot_combined_metrics(hist1, hist2, title):
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Plot accuracy
    axes[0].plot(hist1.history["accuracy"], label="Train - Un canal")
    axes[0].plot(hist1.history["val_accuracy"], label="Validation - Un canal")
    axes[0].plot(hist2.history["accuracy"], label="Train - Dos canales")
    axes[0].plot(hist2.history["val_accuracy"], label="Validation - Dos canales")
    axes[0].set_title("Model Accuracy")
    axes[0].set_ylabel("Accuracy")
    axes[0].set_xlabel("Epoch")
    axes[0].legend(loc="upper left")
    axes[0].set_ylim((0, 1))
    axes[0].grid()

    # Plot loss
    axes[1].plot(hist1.history["loss"], label="Train - Un canal")
    axes[1].plot(hist1.history["val_loss"], label="Validation - Un canal")
    axes[1].plot(hist2.history["loss"], label="Train - Dos canales")
    axes[1].plot(hist2.history["val_loss"], label="Validation - Dos canales")
    axes[1].set_title("Model Loss")
    axes[1].set_ylabel("Loss")
    axes[1].set_xlabel("Epoch")
    axes[1].legend(loc="lower left")
    axes[1].set_ylim((0, 1))
    axes[1].grid()

    plt.suptitle(title)
    plt.show()

# Example usage:
# Assuming you have historial and historial2
plot_combined_metrics(historial, historial2, "Combined Model Metrics")

"""# Callbacks

Aqui se desarrolla el modelo utilizando callbacks para eficientar el tiempo del algoritmo y el procesamiento.
"""

#Callbacks
early_stop = EarlyStopping(monitor='val_mse', patience=10, verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001)

"""## Convulcional 3

Aqui utilizamos los callbacks con un solo canal

### X Y
"""

yc = reshaped_image_2

Xc = reshaped_image

# Assuming reshaped_image is your features and y is your labels
X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

y_train.shape

y_val.shape

X_train.shape

X_val.shape

show(X_train[4, :, :, 0])

show(X_val[1, :, :, 0])

"""### Modelo"""

# Define the neural network architecture
model3 = Sequential()

# Convolutional and max-pooling layers
model3.add(Conv2D(64, (3, 3), activation='relu', input_shape=(50, 50, 1)))
model3.add(MaxPooling2D((2, 2)))
model3.add(Conv2D(128, (3, 3), activation='relu'))
model3.add(MaxPooling2D((2, 2)))

# Flatten layer
model3.add(Flatten())

# Fully connected layers
model3.add(Dense(2500, activation='sigmoid'))

# Reshape to 2D
model3.add(Reshape((50, 50, 1)))

# Compila el modelo
model3.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

# Print model summary
model3.summary()

# Commented out IPython magic to ensure Python compatibility.
# %time historial3 = model3.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_val, X_val), callbacks=[early_stop,reduce_lr])

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial3)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial3)

salida = model3.predict(y_train)
plt.imshow(salida[2, :, :, 0])

"""## Convulcional 4

Aqui utilizamos callbacks con el modelo de dos canales

### X Y
"""

yc2 = reshaped_image_2

Xc2 = reshaped_image2

X_train, X_test, y_train, y_test = train_test_split(Xc2, yc2, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

X_train.shape

show(X_train[2, :, :, 0])

"""### Modelo"""

# Define the neural network architecture
model4 = Sequential()

# Convolutional and max-pooling layers
model4.add(Conv2D(64, (3, 3), activation='relu', input_shape=(50, 50, 2)))  # Change input shape to (50, 50, 2)
model4.add(MaxPooling2D((2, 2)))
model4.add(Conv2D(128, (3, 3), activation='relu'))
model4.add(MaxPooling2D((2, 2)))

# Flatten layer
model4.add(Flatten())

# Fully connected layers
model4.add(Dense(2500, activation='sigmoid'))

# Reshape to 2D
model4.add(Reshape((50, 50, 1)))

# Compile the model
model4.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

# Print model summary
model4.summary()

# Commented out IPython magic to ensure Python compatibility.
# %time historial4 = model2.fit(X_train, X_train, epochs=100, batch_size=32, validation_data=(X_val, X_val), callbacks=[early_stop,reduce_lr])

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial4)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial4)

salida = model4.predict(X_train)
plt.imshow(salida[0, :, :, 0])

# Display the predicted output (1st sample) using matplotlib
plt.imshow(salida[5, :, :, 0], cmap='RdYlGn')  # Assuming it's a grayscale image
plt.colorbar()
plt.title('Predicted Output')
plt.show()

# Get the range of the predicted image
predicted_range = np.ptp(salida[5, :, :, 0])  # Peak-to-peak (max-min) value
print(f"Predicted Image Range: {predicted_range}")

"""## Comparación un canal vs dos canales"""

def plot_metrics(hist, title):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # Plot accuracy
    ax1.plot(hist.history["accuracy"])
    ax1.plot(hist.history["val_accuracy"])
    ax1.set_title("Model Accuracy")
    ax1.set_ylabel("Accuracy")
    ax1.set_xlabel("Epoch")
    ax1.legend(["Train", "Validation"], loc="upper left")
    ax1.set_ylim((0, 1))
    ax1.grid()

    # Plot loss
    ax2.plot(hist.history["loss"])
    ax2.plot(hist.history["val_loss"])
    ax2.set_title("Model Loss")
    ax2.set_ylabel("Loss")
    ax2.set_xlabel("Epoch")
    ax2.legend(["Train", "Validation"], loc="upper left")
    ax2.set_ylim((0, 1))
    ax2.grid()

    plt.suptitle(title)
    plt.show()

# Example usage:
# Assuming you have historial and historial2
plot_metrics(historial3, "Model Metrics - Un canal")
plot_metrics(historial4, "Model Metrics - Dos canales")

def plot_combined_metrics(hist1, hist2, title):
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Plot accuracy
    axes[0].plot(hist1.history["accuracy"], label="Train - Un canal")
    axes[0].plot(hist1.history["val_accuracy"], label="Validation - Un canal")
    axes[0].plot(hist2.history["accuracy"], label="Train - Dos canales")
    axes[0].plot(hist2.history["val_accuracy"], label="Validation - Dos canales")
    axes[0].set_title("Model Accuracy")
    axes[0].set_ylabel("Accuracy")
    axes[0].set_xlabel("Epoch")
    axes[0].legend(loc="upper left")
    axes[0].set_ylim((0, 1))
    axes[0].grid()

    # Plot loss
    axes[1].plot(hist1.history["loss"], label="Train - Un canal")
    axes[1].plot(hist1.history["val_loss"], label="Validation - Un canal")
    axes[1].plot(hist2.history["loss"], label="Train - Dos canales")
    axes[1].plot(hist2.history["val_loss"], label="Validation - Dos canales")
    axes[1].set_title("Model Loss")
    axes[1].set_ylabel("Loss")
    axes[1].set_xlabel("Epoch")
    axes[1].legend(loc="lower left")
    axes[1].set_ylim((0, 1))
    axes[1].grid()

    plt.suptitle(title)
    plt.show()

# Example usage:
# Assuming you have historial and historial2
plot_combined_metrics(historial3, historial4, "Combined Model Metrics")

"""# Distintos LR y optimizadores

Aqui el modelo trabajara con distintos LR y optimizadores

## Convulcional 5

Aqui utilizamos los callbacks con un solo canal

### X Y
"""

ylr = reshaped_image_2

Xlr = reshaped_image

# Assuming reshaped_image is your features and y is your labels
X_train, X_test, y_train, y_test = train_test_split(Xc, yc, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

y_train.shape

y_val.shape

X_train.shape

X_val.shape

show(X_train[4, :, :, 0])

show(X_val[1, :, :, 0])

"""### Modelo"""

# Define the neural network architecture
model5 = Sequential()
model5.add(Conv2D(64, (3, 3), activation='relu', input_shape=(50, 50, 1)))
model5.add(MaxPooling2D((2, 2)))
model5.add(Conv2D(128, (3, 3), activation='relu'))
model5.add(MaxPooling2D((2, 2)))
model5.add(Flatten())
model5.add(Dense(2500, activation='sigmoid'))
model5.add(Reshape((50, 50, 1)))

model5.summary()

# Configura el modelo inicial
config_inicial = model5.get_config()
weights_inicial = model5.get_weights()

# Parámetros para la búsqueda de hiperparámetros
learning_rates = [0.0001, 0.001, 0.01, 0.1,]
batch_sizes = [16, 32, 64]
optimizers = [
    tf.keras.optimizers.legacy.Adam()
]
#    keras.optimizers.SGD(),     keras.optimizers.SGD(momentum=0.9),    keras.optimizers.Nadam()

# Mejores parámetros y resultados iniciales
mejores_parametros_val = {
    'loss': float('inf'),
    'lr': None,
    'opt': None,
    'batch_size': None
}

t = time.time()
contador = 0
ind = 1

total_combinations = len(learning_rates) * len(batch_sizes) * len(optimizers)

for lr in learning_rates:
    for batch_s in batch_sizes:
        for opt in optimizers:
            contador += 1

            # Crea un nuevo modelo en cada iteración y configura pesos
            model = Sequential.from_config(config_inicial)
            model.set_weights(weights_inicial)

            model.compile(optimizer=opt, loss='mse', metrics="accuracy")

            pbar = tqdm(total=100, desc=f'Combinación {contador}/{total_combinations}', unit='epoch', position=0, leave=True)
            for epoch in range(100):
                historial5 = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1, verbose=0, batch_size=batch_s)
                pbar.update(1)
                pbar.set_postfix(loss=historial5.history['loss'][0], val_loss=historial5.history['val_loss'][0])
            pbar.close()

            pred = model.evaluate(X_val, y_val, verbose=0)

            if pred[0] < mejores_parametros_val['loss']:
                        mejores_parametros_val['loss'] = pred[0]
                        mejores_parametros_val['lr'] = lr
                        mejores_parametros_val['opt'] = opt
                        mejores_parametros_val['batch_size'] = batch_s
    print(contador, ') VAL  lr=', lr, ', opt=', opt, 'batch_size=', batch_s, 'loss=', pred[0])
    if pred[0] == 0.0:
        print("Entrenamiento completo :) ")
        ind = 0
        break


        if ind == 0:
            break

    if ind == 0:
        break

print(f'Tiempo de entrenamiento {(time.time() - t)/60:.5f} mins')

# Mejores parámetros y resultados iniciales
mejores_parametros_val = {
    'loss': float('inf'),
    'lr': None,
    'opt': None,
    'batch_size': None
}

mejores_parametros_val

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial5)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial5)

salida = model5.predict(y_train)
plt.imshow(salida[2, :, :, 0])

# Display the predicted output (1st sample) using matplotlib
plt.imshow(salida[4, :, :, 0], cmap='RdYlGn')  # Assuming it's a grayscale image
plt.colorbar()
plt.title('Predicted Output')
plt.show()

# Get the range of the predicted image
predicted_range = np.ptp(salida[4, :, :, 0])  # Peak-to-peak (max-min) value
print(f"Predicted Image Range: {predicted_range}")

"""## Convulcional 6

Aqui utilizamos callbacks con el modelo de dos canales

### X Y
"""

ylr2 = reshaped_image_2

Xlr2 = reshaped_image2

X_train, X_test, y_train, y_test = train_test_split(Xlr2, ylr2, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)

X_val.shape

X_test.shape

X_train.shape

show(X_train[2, :, :, 0])

"""### Modelo"""

# Define the neural network architecture
model6 = Sequential()
model6.add(Conv2D(64, (3, 3), activation='relu', input_shape=(50, 50, 2)))
model6.add(MaxPooling2D((2, 2)))
model6.add(Conv2D(128, (3, 3), activation='relu'))
model6.add(MaxPooling2D((2, 2)))
model6.add(Flatten())
model6.add(Dense(2500, activation='sigmoid'))
model6.add(Reshape((50, 50, 1)))

model6.summary()

# Configura el modelo inicial
config_inicial = model6.get_config()
weights_inicial = model6.get_weights()

# Parámetros para la búsqueda de hiperparámetros
learning_rates = [0.0001, 0.001, 0.01, 0.1,]
batch_sizes = [16, 32, 64]
optimizers = [
    tf.keras.optimizers.legacy.Adam()
]

# Mejores parámetros y resultados iniciales
mejores_parametros_val = {
    'loss': float('inf'),
    'lr': None,
    'opt': None,
    'batch_size': None
}

# Commented out IPython magic to ensure Python compatibility.
# Mejores parámetros y resultados iniciales
mejores_parametros_val = {
    'loss': float('inf'),
    'lr': None,
    'opt': None,
    'batch_size': None
}

t = time.time()
contador = 0
ind = 1

total_combinations = len(learning_rates) * len(batch_sizes) * len(optimizers)

for lr in learning_rates:
    for batch_s in batch_sizes:
        for opt in optimizers:
            contador += 1

            # Crea un nuevo modelo en cada iteración y configura pesos
            model = Sequential.from_config(config_inicial)
            model.set_weights(weights_inicial)

            model.compile(optimizer=opt, loss='mse', metrics="accuracy")

            pbar = tqdm(total=100, desc=f'Combinación {contador}/{total_combinations}', unit='epoch', position=0, leave=True)
            for epoch in range(100):
#                 %time historial5 = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1, verbose=0, batch_size=batch_s)
                pbar.update(1)
                pbar.set_postfix(loss=historial5.history['loss'][0], val_loss=historial5.history['val_loss'][0])
            pbar.close()

            pred = model.evaluate(X_val, y_val, verbose=0)

            if pred[0] < mejores_parametros_val['loss']:
                mejores_parametros_val['loss'] = pred[0]
                mejores_parametros_val['lr'] = lr
                mejores_parametros_val['opt'] = opt
                mejores_parametros_val['batch_size'] = batch_s

            print(contador, ') VAL  lr=', lr, ', opt=', opt, 'batch_size=', batch_s, 'loss=', pred[0])
            if pred[0] == 0.0:
                print("Entrenamiento completo :) ")
                ind = 0
                break

        if ind == 0:
            break

    if ind == 0:
        break

print(f'Tiempo de entrenamiento {(time.time() - t)/60:.5f} mins')

# Mejores parámetros y resultados iniciales
mejores_parametros_val = {
    'loss': float('inf'),
    'lr': None,
    'opt': None,
    'batch_size': None
}

t = time.time()
contador = 0
ind = 1

total_combinations = len(learning_rates) * len(batch_sizes) * len(optimizers)

for lr in learning_rates:
    for batch_s in batch_sizes:
        for opt in optimizers:
            contador += 1

            # Crea un nuevo modelo en cada iteración y configura pesos
            model = Sequential.from_config(config_inicial)
            model.set_weights(weights_inicial)

            model.compile(optimizer=opt, loss='mse', metrics="accuracy")

            pbar = tqdm(total=100, desc=f'Combinación {contador}/{total_combinations}', unit='epoch', position=0, leave=True)
            for epoch in range(100):
                historial5 = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=1, verbose=0, batch_size=batch_s)
                pbar.update(1)
                pbar.set_postfix(loss=historial5.history['loss'][0], val_loss=historial5.history['val_loss'][0])
            pbar.close()

            pred = model.evaluate(X_val, y_val, verbose=0)

            if pred[0] < mejores_parametros_val['loss']:
                        mejores_parametros_val['loss'] = pred[0]
                        mejores_parametros_val['lr'] = lr
                        mejores_parametros_val['opt'] = opt
                        mejores_parametros_val['batch_size'] = batch_s
    print(contador, ') VAL  lr=', lr, ', opt=', opt, 'batch_size=', batch_s, 'loss=', pred[0])
    if pred[0] == 0.0:
        print("Entrenamiento completo :) ")
        ind = 0
        break


        if ind == 0:
            break

    if ind == 0:
        break

print(f'Tiempo de entrenamiento {(time.time() - t)/60:.5f} mins')

mejores_parametros_val

salida = model6.predict(X_train)
plt.imshow(salida[1, :, :, 0])

# Display the predicted output (1st sample) using matplotlib
plt.imshow(salida[2, :, :, 0], cmap='RdYlGn')  # Assuming it's a grayscale image
plt.colorbar()
plt.title('Predicted Output')
plt.show()

# Get the range of the predicted image
predicted_range = np.ptp(salida[2, :, :, 0])  # Peak-to-peak (max-min) value
print(f"Predicted Image Range: {predicted_range}")

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial6)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial6)

mejorModelo = keras.Model.from_config(mejor_config)
mejorModelo.set_weights(mejor_weights)

opt = keras.optimizers.Adam( learning_rate = mejores_parametros_val['lr'] )

mejorModelo.compile(optimizer=opt, loss='mse')

mejorModelo.evaluate( X_val, y_val, verbose = 0 )

salida = model6.predict(X_train)
plt.imshow(salida[0, :, :, 0])

# Display the predicted output (1st sample) using matplotlib
plt.imshow(salida[5, :, :, 0], cmap='RdYlGn')  # Assuming it's a grayscale image
plt.colorbar()
plt.title('Predicted Output')
plt.show()

# Get the range of the predicted image
predicted_range = np.ptp(salida[5, :, :, 0])  # Peak-to-peak (max-min) value
print(f"Predicted Image Range: {predicted_range}")

"""## Comparación un canal vs dos canales"""

def plot_metrics(hist, title):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

    # Plot accuracy
    ax1.plot(hist.history["accuracy"])
    ax1.plot(hist.history["val_accuracy"])
    ax1.set_title("Model Accuracy")
    ax1.set_ylabel("Accuracy")
    ax1.set_xlabel("Epoch")
    ax1.legend(["Train", "Validation"], loc="upper left")
    ax1.set_ylim((0, 1))
    ax1.grid()

    # Plot loss
    ax2.plot(hist.history["loss"])
    ax2.plot(hist.history["val_loss"])
    ax2.set_title("Model Loss")
    ax2.set_ylabel("Loss")
    ax2.set_xlabel("Epoch")
    ax2.legend(["Train", "Validation"], loc="upper left")
    ax2.set_ylim((0, 1))
    ax2.grid()

    plt.suptitle(title)
    plt.show()

# Example usage:
# Assuming you have historial and historial2
plot_metrics(historial5, "Model Metrics - Un canal")
plot_metrics(historial6, "Model Metrics - Dos canales")

def plot_combined_metrics(hist1, hist2, title):
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # Plot accuracy
    axes[0].plot(hist1.history["accuracy"], label="Train - Un canal")
    axes[0].plot(hist1.history["val_accuracy"], label="Validation - Un canal")
    axes[0].plot(hist2.history["accuracy"], label="Train - Dos canales")
    axes[0].plot(hist2.history["val_accuracy"], label="Validation - Dos canales")
    axes[0].set_title("Model Accuracy")
    axes[0].set_ylabel("Accuracy")
    axes[0].set_xlabel("Epoch")
    axes[0].legend(loc="upper left")
    axes[0].set_ylim((0, 1))
    axes[0].grid()

    # Plot loss
    axes[1].plot(hist1.history["loss"], label="Train - Un canal")
    axes[1].plot(hist1.history["val_loss"], label="Validation - Un canal")
    axes[1].plot(hist2.history["loss"], label="Train - Dos canales")
    axes[1].plot(hist2.history["val_loss"], label="Validation - Dos canales")
    axes[1].set_title("Model Loss")
    axes[1].set_ylabel("Loss")
    axes[1].set_xlabel("Epoch")
    axes[1].legend(loc="lower left")
    axes[1].set_ylim((0, 1))
    axes[1].grid()

    plt.suptitle(title)
    plt.show()

# Example usage:
# Assuming you have historial and historial2
plot_combined_metrics(historial5, historia6, "Combined Model Metrics")

"""# ----------------------------------------"""

mi_mejor_modelo.evaluate(X_test,y_test)

y_pred = mi_mejor_modelo.predict(X_test)

from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)

# Print the metrics
print(f'Overall Accuracy (OA): {accuracy:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')

input_layer = Input(shape=(200, 200, 2))
encoder = Conv2D(16, (3, 3), activation="relu", padding="same")(input_layer)
encoder = MaxPooling2D((2, 2))(encoder)
decoder = Conv2D(16, (3, 3), activation="relu", padding="same")(encoder)
decoder = MaxPooling2D((2, 2))(decoder)
decoder1 = Conv2D(16, (3, 3), activation="relu", padding="same")(encoder1)
decoder2 = MaxPooling2D((2, 2))(decoder)
output_layer = Conv2D(2, (3, 3), activation="sigmoid", padding="same")(decoder)

# Crea el modelo del autoencoder
autoencoder = Model(input_layer, output_layer)

# Compila el modelo
autoencoder.compile(optimizer="adam", loss="binary_crossentropy", metrics=['accuracy'])

autoencoder.summary()

# Commented out IPython magic to ensure Python compatibility.
# Entrena el autoencoder
# %time historial=autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_data=(X_test, X_test))

salida = autoencoder.predict(X_train)
plt.imshow(salida[2, :, :, 0])

def plot_hist(hist):
    plt.plot(hist.history["accuracy"])
    plt.plot(hist.history["val_accuracy"])
    plt.title("model accuracy")
    plt.ylabel("accuracy")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist(historial)

activations = get_activations(autoencoder, salida)
display_activations(activations, cmap="gray", save=False)

def plot_hist_loss(hist):
    plt.plot(hist.history["loss"])
    plt.plot(hist.history["val_loss"])
    plt.title("model loss")
    plt.ylabel("loss")
    plt.xlabel("epoch")
    plt.legend(["train", "validation"], loc="upper left")
    plt.ylim((0,1))
    plt.grid()
    plt.show()


plot_hist_loss(historial)